"""
Startup script for Kokoro TTS Streaming Server
Handles GPU detection and optimal configuration
"""

import sys
import torch
import logging
from pathlib import Path

def check_gpu():
    """Check GPU availability and configuration"""
    print("ğŸ” Checking GPU configuration...")
    
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_device)
        gpu_memory = torch.cuda.get_device_properties(current_device).total_memory / 1e9
        
        print(f"âœ… CUDA available: {torch.version.cuda}")
        print(f"ğŸ® GPU Count: {gpu_count}")
        print(f"ğŸš€ Current GPU: {gpu_name}")
        print(f"ğŸ’¾ GPU Memory: {gpu_memory:.1f} GB")
        
        # Test GPU memory allocation
        try:
            test_tensor = torch.randn(1000, 1000, device='cuda')
            del test_tensor
            torch.cuda.empty_cache()
            print("âœ… GPU memory test passed")
        except Exception as e:
            print(f"âš ï¸  GPU memory test failed: {e}")
            return False
            
        return True
    else:
        print("âŒ CUDA not available - will use CPU (slower)")
        return False

def check_model():
    """Check if Kokoro model is available"""
    print("\nğŸ” Checking Kokoro model...")
    
    try:
        from kokoro import KPipeline
        print("Kokoro library found")
        
        # Test model loading
        pipeline = KPipeline(lang_code='a', device='cuda' if torch.cuda.is_available() else 'cpu')
        test_gen = pipeline("Test", voice="af_heart")
        test_result = next(iter(test_gen))
        
        if len(test_result) >= 3 and test_result[2] is not None:
            print("Kokoro model test passed")
            return True
        else:
            print("âŒ Kokoro model test failed - no audio generated")
            return False
            
    except ImportError as e:
        print(f"âŒ Kokoro library not found: {e}")
        print("ğŸ’¡ Install with: pip install kokoro")
        return False
    except Exception as e:
        print(f"âŒ Kokoro model test failed: {e}")
        return False

def check_dependencies():
    """Check all dependencies"""
    print("\nğŸ” Checking dependencies...")
    
    required_packages = [
        "fastapi", "uvicorn", "websockets", "soundfile", "numpy"
    ]
    
    missing = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package}")
            missing.append(package)
    
    if missing:
        print(f"\nğŸ’¡ Install missing packages: pip install {' '.join(missing)}")
        return False
    
    return True

def main():
    """Main startup function"""
    print("Kokoro TTS Streaming Server Startup")
    print("=" * 50)
    
    # Check dependencies
    if not check_dependencies():
        print("\nâŒ Dependency check failed")
        sys.exit(1)
    
    # Check GPU
    gpu_available = check_gpu()
    
    # Check model
    if not check_model():
        print("\nâŒ Model check failed")
        sys.exit(1)
    
    print("\n" + "=" * 50)
    print("ğŸš€ All checks passed! Starting server...")
    print("ğŸŒ Server will be available at: http://localhost:8000")
    print("âš¡ GPU Acceleration:", "Enabled" if gpu_available else "Disabled")
    print("=" * 50)
    
    # Start the server
    try:
        import uvicorn
        from server import app
        
        uvicorn.run(
            app,
            host="0.0.0.0", 
            port=8000,
            log_level="info",
            access_log=True
        )
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Server stopped by user")
    except Exception as e:
        print(f"\nâŒ Server error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
